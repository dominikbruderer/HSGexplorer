# recommender.py
"""
Empfehlungssystem: Funktionen f√ºr personalisierte Vorschl√§ge.

Dieses Modul enth√§lt die Logik, um Nutzern Aktivit√§ten vorzuschlagen,
die ihrem Geschmack √§hneln k√∂nnten, basierend auf dem, was sie zuvor
positiv ("Like" üëç) bewertet haben.

Stell dir vor, die App lernt, was dir gef√§llt, und nutzt dieses Wissen,
um passende neue Aktivit√§ten zu finden.

Hauptaufgaben hier drin:
1. Aktivit√§ten analysieren und "verstehen" (sie in Zahlen √ºbersetzen).
2. Ein "Geschmacksprofil" f√ºr den Nutzer erstellen (basierend auf Likes).
3. Aktivit√§ten finden, die gut zum Geschmacksprofil passen.
4. Helfen, das Gelernte anzuzeigen (z.B. welche Arten du magst).
"""

import pandas as pd
import numpy as np
# import scipy.sparse # Wahrscheinlich nicht direkt ben√∂tigt
import random # F√ºr zuf√§llige "√úberraschungs"-Vorschl√§ge
from collections import Counter # Zum Z√§hlen von Elementen (z.B. Zielgruppen)
from typing import Tuple, Optional, List, Dict, Any, Set # Nur technische Typ-Hinweise f√ºr Entwickler

# Ben√∂tigte Werkzeuge aus der scikit-learn Bibliothek f√ºr die Datenanalyse/Empfehlungen
from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity # Zum Berechnen der √Ñhnlichkeit

# Lade die Spaltennamen aus unserer Konfigurationsdatei (config.py)
try:
    from config import (
        COL_ID, COL_NAME, COL_ART, COL_ZIELGRUPPE, COL_INDOOR_OUTDOOR,
        COL_PREIS, COL_BESCHREIBUNG
    )
except ImportError:
    print("FATAL: config.py konnte nicht importiert werden (recommender.py).")
    # Notfall-Werte:
    COL_ID, COL_NAME = 'ID', 'Name'; COL_ART, COL_ZIELGRUPPE = 'Art', 'Zielgruppe'
    COL_INDOOR_OUTDOOR, COL_PREIS = 'Indoor_Outdoor', 'Preis_Ca'; COL_BESCHREIBUNG = 'Beschreibung'


def preprocess_features(df: pd.DataFrame) -> Tuple[None, Optional[np.ndarray]]:
    """
    Bereitet die Aktivit√§tsdaten f√ºr den Computer auf, damit er sie vergleichen kann.

    Computer k√∂nnen nicht direkt Text oder Kategorien vergleichen. Diese Funktion
    wandelt alle relevanten Informationen √ºber eine Aktivit√§t (wie Beschreibung,
    Art, Preis, Zielgruppe) in eine Reihe von Zahlen um. Man kann sich das wie
    einen einzigartigen "digitalen Fingerabdruck" f√ºr jede Aktivit√§t vorstellen.
    Diese Fingerabdr√ºcke k√∂nnen dann mathematisch verglichen werden, um √Ñhnlichkeiten
    zu finden.

    Wie die Umwandlung (vereinfacht) funktioniert:
    - **Beschreibungstext:** Analysiert den Text, findet wichtige Schl√ºsselw√∂rter
      und bewertet deren Wichtigkeit f√ºr jede Aktivit√§t. Das Ergebnis sind Zahlen.
    - **Zielgruppen (z.B. "Familie, Kinder"):** Macht aus jeder m√∂glichen Zielgruppe
      eine Art "Ja/Nein"-Frage (Ist diese Aktivit√§t f√ºr Familien? Ja/Nein).
    - **Preis:** Bringt alle Preise auf eine einheitliche Skala (z.B. zwischen 0 und 1),
      damit teure Aktivit√§ten nicht automatisch "un√§hnlicher" sind.
    - **Art & Indoor/Outdoor (z.B. "Kultur", "Indoor"):** Macht ebenfalls aus jeder
      M√∂glichkeit eine "Ja/Nein"-Frage (Ist es Kultur? Ja/Nein. Ist es Indoor? Ja/Nein).

    Args:
        df (pd.DataFrame): Die Tabelle mit den urspr√ºnglichen Aktivit√§tsdaten.

    Returns:
        Tuple[None, Optional[np.ndarray]]:
        - Internes Objekt (None): Wird nicht weiter ben√∂tigt.
        - features (Optional[np.ndarray]): Die Tabelle mit den "digitalen Fingerabdr√ºcken".
                                         Jede Zeile ist eine Aktivit√§t, jede Spalte eine
                                         Zahl, die ein Merkmal beschreibt. Gibt None
                                         zur√ºck, wenn etwas schiefgeht.
    """
    if df.empty:
        print("WARNUNG (preprocess): Leere Tabelle zum Vorbereiten erhalten.")
        return None, None

    df_processed = df.copy()
    final_features_list = [] # Hier sammeln wir die einzelnen Zahlen-Teile

    # --- 1. Textbeschreibung analysieren ---
    if COL_BESCHREIBUNG in df_processed.columns:
        df_processed[COL_BESCHREIBUNG] = df_processed[COL_BESCHREIBUNG].fillna('').astype(str)
        # Werkzeug zur Textanalyse initialisieren (ignoriert unwichtige F√ºllw√∂rter)
        vectorizer = TfidfVectorizer(stop_words=None, max_features=500, ngram_range=(1, 2))
        try:
            # Text in Zahlen umwandeln
            tfidf_features = vectorizer.fit_transform(df_processed[COL_BESCHREIBUNG])
            final_features_list.append(tfidf_features.toarray()) # Als normalen Zahlenteil hinzuf√ºgen
        except Exception as e:
            print(f"FEHLER (preprocess): Textanalyse fehlgeschlagen: {e}")
            pass # Mache trotzdem weiter, vielleicht klappen die anderen Teile

    # --- 2. Zielgruppen analysieren (Mehrfachauswahl m√∂glich) ---
    if COL_ZIELGRUPPE in df_processed.columns:
        df_processed[COL_ZIELGRUPPE] = df_processed[COL_ZIELGRUPPE].fillna('').astype(str)
        # Teile "Familie, Kinder" in ["Familie", "Kinder"] auf
        df_processed[COL_ZIELGRUPPE] = df_processed[COL_ZIELGRUPPE].apply(
            lambda x: [tag.strip() for tag in x.split(',') if tag.strip()]
        )
        if any(df_processed[COL_ZIELGRUPPE]):
            # Werkzeug, das f√ºr jede Zielgruppe eine Ja/Nein-Spalte erzeugt
            mlb = MultiLabelBinarizer()
            try:
                # Zielgruppen in Ja/Nein-Zahlen (0/1) umwandeln
                zielgruppe_features = mlb.fit_transform(df_processed[COL_ZIELGRUPPE])
                final_features_list.append(zielgruppe_features)
            except Exception as e:
                print(f"FEHLER (preprocess): Zielgruppen-Analyse fehlgeschlagen: {e}")
                pass

    # --- 3. Preis, Aktivit√§tsart, Indoor/Outdoor analysieren ---
    numeric_features = [COL_PREIS] # Spalten mit einfachen Zahlen
    categorical_features_ohe = [COL_ART, COL_INDOOR_OUTDOOR] # Spalten mit Kategorien (Einfachauswahl)

    # Werkzeuge vorbereiten: Eins zum Skalieren von Zahlen, eins f√ºr Kategorien
    numeric_transformer = Pipeline(steps=[('scaler', MinMaxScaler())]) # Bringt Zahlen auf 0-1 Skala
    categorical_transformer_ohe = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]) # Macht Ja/Nein-Spalten

    # Baue einen Plan zusammen, welches Werkzeug auf welche Spalte angewendet wird
    transformers_list = []
    valid_numeric_features = [col for col in numeric_features if col in df_processed.columns]
    if valid_numeric_features:
         df_processed[valid_numeric_features] = df_processed[valid_numeric_features].fillna(0) # Fehlende Preise als 0 behandeln
         transformers_list.append(('num', numeric_transformer, valid_numeric_features))

    valid_ohe_features = [col for col in categorical_features_ohe if col in df_processed.columns]
    if valid_ohe_features:
         for col in valid_ohe_features: df_processed[col] = df_processed[col].fillna('Unbekannt') # Fehlende Kategorien als 'Unbekannt'
         transformers_list.append(('cat_ohe', categorical_transformer_ohe, valid_ohe_features))

    # Wende den Plan an, wenn es was zu tun gibt
    if transformers_list:
        # F√ºhrt die Skalierung und Kategorien-Umwandlung durch
        preprocessor_ct = ColumnTransformer(transformers=transformers_list, remainder='drop')
        try:
            ct_features = preprocessor_ct.fit_transform(df_processed)
            final_features_list.append(ct_features)
        except Exception as e:
            print(f"FEHLER (preprocess): Preis/Art/Ort-Analyse fehlgeschlagen: {e}")
            pass

    # --- 4. Alle Zahlen-Teile zum finalen "Fingerabdruck" zusammenf√ºgen ---
    if not final_features_list:
        print("WARNUNG (preprocess): Konnte keine Merkmale extrahieren.")
        return None, None
    try:
        # H√§ngt alle Zahlenreihen (aus Text, Zielgruppe, Preis etc.) aneinander
        final_features_matrix = np.hstack(final_features_list)
        print(f"INFO (preprocess): 'Digitale Fingerabdr√ºcke' erstellt (Form: {final_features_matrix.shape})")
        return None, final_features_matrix
    except Exception as e:
        print(f"FEHLER (preprocess): Beim Zusammenf√ºgen der Merkmale: {e}")
        return None, None


def calculate_user_profile(
    liked_ids: List[int],
    disliked_ids: List[int], # Info: Dislikes werden momentan nicht f√ºrs Profil genutzt
    features_matrix: Optional[np.ndarray],
    df: pd.DataFrame
    ) -> Optional[np.ndarray]:
    """
    Erstellt ein pers√∂nliches "Geschmacksprofil" basierend auf den Likes des Nutzers.

    Das Profil ist quasi der durchschnittliche "digitale Fingerabdruck" aller
    Aktivit√§ten, die der Nutzer mit "Like" üëç bewertet hat. Es repr√§sentiert,
    welche Merkmale (aus Beschreibung, Art, Preis etc.) der Nutzer tendenziell bevorzugt.

    Args:
        liked_ids (List[int]): Die IDs der Aktivit√§ten, die der Nutzer geliked hat.
        disliked_ids (List[int]): IDs der nicht gemochten Aktivit√§ten (aktuell ignoriert).
        features_matrix (Optional[np.ndarray]): Die Tabelle mit den "digitalen Fingerabdr√ºcken"
                                             aller Aktivit√§ten (von `preprocess_features`).
        df (pd.DataFrame): Die urspr√ºngliche Aktivit√§tstabelle (um IDs zu finden).

    Returns:
        Optional[np.ndarray]: Der "Geschmacks-Fingerabdruck" des Nutzers als Zahlenreihe,
                               oder None, wenn keine Likes vorhanden sind oder Fehler auftreten.
    """
    if features_matrix is None or features_matrix.shape[1] == 0 or df.empty:
        return None # Geht nicht ohne Fingerabdr√ºcke oder Originaldaten
    if not liked_ids:
         return None # Geht nicht ohne Likes

    try:
        # Finde heraus, welche Zeilen in der Fingerabdruck-Tabelle zu den gelikten IDs geh√∂ren
        df[COL_ID] = pd.to_numeric(df[COL_ID], errors='coerce').fillna(-1).astype(int)
        liked_indices = df.index[df[COL_ID].isin(liked_ids)].tolist()
        if not liked_indices: return None
        valid_indices = [idx for idx in liked_indices if idx < features_matrix.shape[0]]
        if not valid_indices: return None
        # Hole die "Fingerabdr√ºcke" der gelikten Aktivit√§ten
        liked_vectors = features_matrix[valid_indices]
    except Exception as e:
        print(f"FEHLER (user_profile): Konnte Likes nicht den Fingerabdr√ºcken zuordnen: {e}")
        return None

    try:
        # Berechne den Durchschnitt f√ºr jedes Merkmal √ºber alle gelikten Fingerabdr√ºcke hinweg.
        # Das Ergebnis ist der durchschnittliche Fingerabdruck = das Geschmacksprofil.
        user_profile_vector = np.mean(liked_vectors, axis=0) # axis=0 hei√üt "durchschnitt pro Spalte"
        return user_profile_vector
    except Exception as e:
        print(f"FEHLER (user_profile): Konnte Durchschnitts-Geschmack nicht berechnen: {e}")
        return None


def get_profile_recommendations(
    user_profile: Optional[np.ndarray],
    features_matrix: Optional[np.ndarray],
    df: pd.DataFrame,
    rated_ids: Set[int], # IDs aller Aktivit√§ten, die der Nutzer schon bewertet hat (Like ODER Dislike)
    n: int = 5, # Wie viele Empfehlungen sollen maximal generiert werden?
    exploration_rate: float = 0.15 # Chance (hier 15%), einen zuf√§lligen Vorschlag einzumischen
    ) -> List[int]:
    """
    Findet Aktivit√§ten, die dem Geschmacksprofil des Nutzers √§hneln.

    Vergleicht den "Geschmacks-Fingerabdruck" des Nutzers mit dem "digitalen
    Fingerabdruck" jeder einzelnen Aktivit√§t. Die Aktivit√§ten, deren Fingerabdruck
    dem Geschmacksprofil am √§hnlichsten ist, werden als Empfehlung vorgeschlagen.
    Bereits bewertete Aktivit√§ten werden dabei √ºbersprungen.

    Manchmal wird auch ein zuf√§lliger Vorschlag eingemischt, damit der Nutzer
    auch mal etwas ganz Neues entdecken kann (das nennt man "Exploration").

    Args:
        user_profile (Optional[np.ndarray]): Der "Geschmacks-Fingerabdruck" des Nutzers.
        features_matrix (Optional[np.ndarray]): Die "digitalen Fingerabdr√ºcke" aller Aktivit√§ten.
        df (pd.DataFrame): Die urspr√ºngliche Aktivit√§tstabelle.
        rated_ids (Set[int]): Die IDs der bereits bewerteten Aktivit√§ten.
        n (int): Maximale Anzahl an Empfehlungen.
        exploration_rate (float): Die Wahrscheinlichkeit f√ºr einen "√úberraschungs"-Vorschlag.

    Returns:
        List[int]: Eine Liste mit den IDs der empfohlenen Aktivit√§ten. Die Reihenfolge ist
                   am Ende zuf√§llig. Kann leer sein, wenn nichts Passendes gefunden wird.
    """
    if user_profile is None or features_matrix is None or features_matrix.shape[1] == 0 or df.empty:
        return [] # Keine Empfehlungen m√∂glich

    # Technische Vorbereitung f√ºr den √Ñhnlichkeitsvergleich
    if user_profile.ndim == 1:
        user_profile = user_profile.reshape(1, -1)

    try:
        # Berechne f√ºr jede Aktivit√§t einen √Ñhnlichkeits-Score (zwischen 0 und 1)
        # zum Geschmacksprofil des Nutzers. Ein Score nahe 1 bedeutet sehr √§hnlich.
        # (Die Methode heisst Kosinus-√Ñhnlichkeit).
        profile_similarities = cosine_similarity(user_profile, features_matrix)
        # Merke dir zu jedem Score, zu welcher Aktivit√§t (Index) er geh√∂rt.
        sim_scores_with_indices = list(enumerate(profile_similarities[0]))
    except Exception as e:
         print(f"FEHLER (profile_recs): √Ñhnlichkeitsberechnung fehlgeschlagen: {e}")
         return []

    # Sortiere die Aktivit√§ten: Die √§hnlichsten zuerst.
    sim_scores_with_indices.sort(key=lambda x: x[1], reverse=True)

    # Gehe die sortierte Liste durch und sammle die Top-N Aktivit√§ten,
    # die der Nutzer noch nicht bewertet hat.
    recommended_ids: List[int] = []
    try:
        df[COL_ID] = pd.to_numeric(df[COL_ID], errors='coerce').fillna(-1).astype(int)
        for index, score in sim_scores_with_indices:
            if len(recommended_ids) >= n: # Genug Empfehlungen gefunden? Stopp!
                break
            activity_id = df.iloc[index].get(COL_ID) # ID der Aktivit√§t holen
            # Ist die ID g√ºltig und wurde sie noch NICHT bewertet?
            if activity_id is not None and activity_id != -1 and activity_id not in rated_ids:
                 recommended_ids.append(int(activity_id)) # Dann zur Liste hinzuf√ºgen
    except Exception as e:
        print(f"FEHLER (profile_recs): Beim Ausw√§hlen der Top-Empfehlungen: {e}")
        # Gib zur√ºck, was bisher gefunden wurde
        return recommended_ids

    # --- Exploration: F√ºge eventuell einen zuf√§lligen Vorschlag hinzu ---
    if random.random() < exploration_rate and not df.empty: # Mit 15% Wahrscheinlichkeit
        # Finde alle IDs, die noch nicht bewertet wurden
        all_ids = df[COL_ID].dropna().unique().tolist()
        unrated_ids = [id_ for id_ in all_ids if isinstance(id_, (int, float)) and pd.notna(id_) and int(id_) not in rated_ids and int(id_) != -1]
        valid_unrated_ids_int = [int(id_) for id_ in unrated_ids]

        if valid_unrated_ids_int:
            random_id = random.choice(valid_unrated_ids_int) # W√§hle eine zuf√§llige ID
            # F√ºge sie hinzu/ersetze eine, wenn sie noch nicht drin ist
            if random_id not in recommended_ids:
                 if len(recommended_ids) < n:
                     recommended_ids.insert(0, random_id) # Vorne einf√ºgen
                 elif len(recommended_ids) == n:
                     recommended_ids[-1] = random_id # Letzte (un√§hnlichste) ersetzen

    # Mische die finale Liste, damit nicht immer die √§hnlichste zuerst kommt.
    random.shuffle(recommended_ids)
    return recommended_ids


# --- Hilfsfunktionen f√ºr die Visualisierung ("Was mag ich?") ---
# Diese Funktionen schauen sich die gelikten Aktivit√§ten an und bereiten
# Informationen auf, die dem Nutzer im Personalisierungs-Bereich angezeigt werden.

def calculate_preference_scores(
    liked_ids: List[int],
    df_all_activities: pd.DataFrame
    ) -> Optional[pd.Series]:
    """ Z√§hlt, wie oft jede Aktivit√§ts-ART (Kultur, Sport etc.) geliked wurde. """
    if not liked_ids or df_all_activities.empty: return None
    if COL_ID not in df_all_activities.columns or COL_ART not in df_all_activities.columns: return None
    try:
        valid_liked_ids = [int(i) for i in liked_ids if isinstance(i, (int, float)) and pd.notna(i)]
        if not valid_liked_ids: return None
        # Finde alle Aktivit√§ten, die geliked wurden
        liked_activities = df_all_activities[df_all_activities[COL_ID].isin(valid_liked_ids)]
        if liked_activities.empty: return None
        # Z√§hle, wie oft jede Art vorkommt
        preference_scores = liked_activities[COL_ART].fillna('Unbekannt').value_counts()
        # Gibt eine Liste zur√ºck, z.B. [("Kultur", 5), ("Natur", 2), ...]
        return preference_scores
    except Exception as e:
        print(f"FEHLER (pref_scores): Konnte Like-Scores (Art) nicht berechnen: {e}")
        return None

def generate_profile_label(preference_scores: Optional[pd.Series]) -> Optional[str]:
    """ Erzeugt einen kurzen Text, der den Nutzertyp beschreibt (z.B. "Kultur-Fan"). """
    if preference_scores is None or preference_scores.empty: return None
    try:
        # Finde die 1-2 am h√§ufigsten gelikten Arten
        sorted_scores = preference_scores.sort_values(ascending=False)
        top_arten = sorted_scores.head(2).index.tolist(); top_scores = sorted_scores.head(2).values.tolist()
        if not top_arten: return None

        # Baue das Label zusammen
        label_parts = []
        if len(top_arten) == 1: label_parts.append(f"{top_arten[0]}-Fan") # Nur eine Art geliked
        elif len(top_arten) == 2: # Zwei Arten geliked
            art1, art2 = top_arten[0], top_arten[1]; score1, score2 = top_scores[0], top_scores[1]
            # Spezielle Namen f√ºr bestimmte Kombinationen
            if {art1, art2} == {"Sport", "Action"}: label_parts.append("Sport & Action Typ")
            elif {art1, art2} == {"Natur", "Wandern"}: label_parts.append("Naturfreund")
            elif {art1, art2} == {"Genuss", "Shopping"}: label_parts.append("Genuss & Shopping Typ")
            # Allgemeinere Namen
            elif score1 > score2 * 1.5: label_parts.append(f"{art1}-Fan (Interesse: {art2})") # Eine Art klar vorne
            else: label_parts.append(f"{art1} & {art2} Typ") # Beide √§hnlich oft

        final_label = " ".join(label_parts)
        return final_label.strip() if final_label else None
    except Exception as e:
        print(f"FEHLER (profile_label): Konnte Profil-Label nicht erstellen: {e}")
        return None

def calculate_top_target_groups(
    liked_ids: List[int],
    df_all_activities: pd.DataFrame,
    top_n: int = 5
    ) -> Optional[pd.Series]:
    """ Findet die Top-Zielgruppen (z.B. Familie, Paare), die in den Likes vorkommen. """
    if not liked_ids or df_all_activities.empty: return None
    if COL_ID not in df_all_activities.columns or COL_ZIELGRUPPE not in df_all_activities.columns: return None
    try:
        valid_liked_ids = [int(i) for i in liked_ids if isinstance(i, (int, float)) and pd.notna(i)]
        if not valid_liked_ids: return None
        liked_activities = df_all_activities[df_all_activities[COL_ID].isin(valid_liked_ids)]
        if liked_activities.empty: return None

        # Sammle alle einzelnen Zielgruppen-Tags (aus "Familie, Kinder" wird "Familie" und "Kinder")
        all_tags = []
        zielgruppen_series = liked_activities[COL_ZIELGRUPPE].fillna('')
        for entry in zielgruppen_series:
            tags = [tag.strip() for tag in entry.split(',') if tag.strip()]
            all_tags.extend(tags)
        if not all_tags: return None

        # Z√§hle, wie oft jede Zielgruppe vorkommt und gib die h√§ufigsten zur√ºck
        tag_counts = Counter(all_tags)
        top_tags_series = pd.Series(tag_counts).sort_values(ascending=False).head(top_n)
        # Gibt eine Liste zur√ºck, z.B. [("Familie", 4), ("Kinder", 3), ...]
        return top_tags_series
    except Exception as e:
        print(f"FEHLER (top_groups): Konnte Top-Zielgruppen nicht berechnen: {e}")
        return None

def get_liked_prices(
    liked_ids: List[int],
    df_all_activities: pd.DataFrame,
    include_free: bool = False # Sollen kostenlose Aktivit√§ten (Preis=0) mitgez√§hlt werden?
    ) -> Optional[List[float]]:
    """ Sammelt die Preise aller Aktivit√§ten, die der Nutzer geliked hat. """
    if not liked_ids or df_all_activities.empty: return None
    if COL_ID not in df_all_activities.columns or COL_PREIS not in df_all_activities.columns: return None
    try:
        valid_liked_ids = [int(i) for i in liked_ids if isinstance(i, (int, float)) and pd.notna(i)]
        if not valid_liked_ids: return None
        liked_activities = df_all_activities[df_all_activities[COL_ID].isin(valid_liked_ids)]
        if liked_activities.empty: return None

        # Hole die Preise und wandle sie in Zahlen um
        prices_numeric = pd.to_numeric(liked_activities[COL_PREIS], errors='coerce')

        # Filtere die g√ºltigen Preise heraus (und ignoriere ggf. die kostenlosen)
        if include_free:
            valid_prices = prices_numeric.dropna().tolist() # Nimm alle g√ºltigen Preise
        else:
            valid_prices = prices_numeric[prices_numeric > 0].dropna().tolist() # Nur Preise √ºber 0

        return valid_prices if valid_prices else None # Gib die Liste der Preise zur√ºck
    except Exception as e:
        print(f"FEHLER (liked_prices): Konnte Preise der Likes nicht sammeln: {e}")
        return None